{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KatharinaGardens/computational-linguistics.github.io/blob/main/LELA32052_Coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1TkziyV4x1w"
      },
      "source": [
        "# LELA32052 Coursework Assignment\n",
        "\n",
        "This document contains instructions, guidance and code for the coursework assignment for this module.\n",
        "\n",
        "The assignment focuses on the task of intent classification. You heard about this in the lecture on dialogue systems, and read about it in this week's reading. It is an important step in modern task-based dialogue systems - given a particular piece of input from the speaker, the system tries to determine what goal the speaker is trying to achieve, in order that it can then produce an appropriate response.\n",
        "\n",
        "Your task is to build a system that takes a transcribed user utterance as input and outputs one of seven different intents:\n",
        "\n",
        "'PlayMusic', e.g. \"play easy listening\" <br>\n",
        "'AddToPlaylist' e.g. \"please add this song to road trip\" <br>\n",
        "'RateBook' e.g. \"give this novel 5 stars\"  <br>\n",
        "'SearchScreeningEvent' e.g. \"give me a list of local movie times\"  <br>\n",
        "'BookRestaurant' e.g. \"i'd like a table for four at 7pm at Asti\"   <br>\n",
        "'GetWeather' e.g. \"what's it like outside\"  <br>\n",
        "'SearchCreativeWork' \"show me the new James Bond trailer\"  <br>\n",
        "\n",
        "You are going to evaluate the performance of this system using a test set of 700 user utterances.\n",
        "\n",
        "In order to create the system you have a training set of 700 utterances and a validation/development set of 700 utterances.\n",
        "\n",
        "This notebook contains code that you can use in the development of your system. Once you have created and evaluated your system, you are going to write a report of no more than 2000 words that describes and evaluates the task, the system and the experiments.\n",
        "\n",
        "A guide as to what should go in your report can be found [here]( https://www.dropbox.com/s/zlmbk60a4ei1jdh/Writing%20your%20Computational%20Linguistics%20Research%20Report.docx)\n",
        "\n",
        "Your report should be submitted via turnitin using the link on Blackboard. You should create a PDF of your notebook and add it as an appendix to your report (not included in word count).  This is just so that I can check what you have done if it isn't clear from your report. You will not be marked on the quality of any code you might include.\n",
        "\n",
        "Please feel free to ask any questions about any part of the coursework. So that my response can benefit everyone please do so using the Coursework Discussion board on Blackboard. You can find a link to this down the left of the module Blackboard page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZTKYPQXlkwp"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9mhOx9Fo5O_"
      },
      "source": [
        "### Link drive\n",
        "\n",
        "Before you begin to build a system, there are a few steps necessary to set things up. The first of these is to link Colab to your Google Drive so that you can save files there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-FysoS88uoHa",
        "outputId": "a7930e33-7947-4405-9341-894bddd96abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "mkdir: cannot create directory ‘/content/gdrive/My Drive/Intent_Classification/’: File exists\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!mkdir /content/gdrive/My\\ Drive/Intent_Classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBlQGSqdhYEq"
      },
      "source": [
        "### Download data and some utilities\n",
        "\n",
        "The next step is to download the data and some supporting code for the project and move it over to the Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GTM-h_dLypXc",
        "outputId": "ad45578a-be98-4fa6-bcd2-c050d2451718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-15 12:06:04--  https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/intent_classification_with_splits.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 139084 (136K) [text/plain]\n",
            "Saving to: ‘intent_classification_with_splits.csv’\n",
            "\n",
            "\r          intent_cl   0%[                    ]       0  --.-KB/s               \rintent_classificati 100%[===================>] 135.82K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-04-15 12:06:04 (4.17 MB/s) - ‘intent_classification_with_splits.csv’ saved [139084/139084]\n",
            "\n",
            "--2025-04-15 12:06:04--  https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/model.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2143 (2.1K) [application/octet-stream]\n",
            "Saving to: ‘model.pth’\n",
            "\n",
            "model.pth           100%[===================>]   2.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-04-15 12:06:05 (24.1 MB/s) - ‘model.pth’ saved [2143/2143]\n",
            "\n",
            "--2025-04-15 12:06:05--  https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/nn_tools.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12574 (12K) [text/plain]\n",
            "Saving to: ‘nn_tools.py’\n",
            "\n",
            "nn_tools.py         100%[===================>]  12.28K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-04-15 12:06:05 (16.8 MB/s) - ‘nn_tools.py’ saved [12574/12574]\n",
            "\n",
            "--2025-04-15 12:06:05--  https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/nn_tools2.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14989 (15K) [text/plain]\n",
            "Saving to: ‘nn_tools2.py’\n",
            "\n",
            "nn_tools2.py        100%[===================>]  14.64K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-04-15 12:06:05 (9.16 MB/s) - ‘nn_tools2.py’ saved [14989/14989]\n",
            "\n",
            "--2025-04-15 12:06:05--  https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/vectorizer.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 756 [text/plain]\n",
            "Saving to: ‘vectorizer.json’\n",
            "\n",
            "vectorizer.json     100%[===================>]     756  --.-KB/s    in 0s      \n",
            "\n",
            "2025-04-15 12:06:05 (37.9 MB/s) - ‘vectorizer.json’ saved [756/756]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/intent_classification_with_splits.csv\n",
        "!wget https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/model.pth\n",
        "!wget https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/nn_tools.py\n",
        "!wget https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/nn_tools2.py\n",
        "!wget https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/vectorizer.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omZSU3G3an8z"
      },
      "source": [
        "### Import packages\n",
        "\n",
        "Finally we need to import some packages to use later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hGm07r91HRN0"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook\n",
        "from nn_tools import Vocabulary, IntentVectorizer, IntentDataset, IntentClassifier\n",
        "from nn_tools2 import *\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5lUe_HTHAre"
      },
      "source": [
        "## Rule-based approach\n",
        "\n",
        "Your task here is to create a classifier using rules, in the form of regular expressions. I have provided you with the basic code for doing this. You will just need to edit the regular expressions in order to improve performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zJle8ZcomM5"
      },
      "source": [
        "### Loading and inspecting project data\n",
        "A valuable first step in order to understand the task is to inspect the data in order to understand the different intents being detected.\n",
        "\n",
        "First you need to load the data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oFqX30mBqOeS"
      },
      "outputs": [],
      "source": [
        "intent_data=pd.read_csv('intent_classification_with_splits.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VKwiv3tzF-R"
      },
      "source": [
        "You can then examine example utterances for each of the intent types as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeWQDiVGmDrl"
      },
      "source": [
        "##### Play Music examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bP0TJCpar3TM",
        "outputId": "27367f12-06e3-47c2-baf0-7b9e37c72bfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3755509c541e>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"PlayMusic\"][\"text\"].head(10).tolist() #added missing parentheses\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['listen to westbam alumb allergic on google music',\n",
              " 'play the song little robin redbreast',\n",
              " 'i want to listen to seventies music',\n",
              " 'play a popular chant by brian epstein',\n",
              " 'can you play me some eighties music by adele',\n",
              " 'play the top-20 best chicane songs on deezer',\n",
              " 'play playlist the realest down south',\n",
              " 'play a chant by mj cole',\n",
              " 'play all of your toys by chris ledoux',\n",
              " 'i want to hear a joel hastings melody']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"PlayMusic\"][\"text\"].head(10).tolist() #added missing parentheses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9MTykZ5qZo8"
      },
      "source": [
        "##### AddToPlaylist examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9TXSUlg5nToK",
        "outputId": "1ede10e6-8fc7-4e08-b13f-ad96fe839a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-ac5fe56b1c24>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"AddToPlaylist\"][\"text\"].head(10).tolist()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['add step to me to the 50 clásicos playlist',\n",
              " 'please add iris dement to my playlist this is selena',\n",
              " 'add slimm cutta calhoun to my this is prince playlist',\n",
              " 'add to playlist confidence boost here comes santa claus',\n",
              " 'add another artist to the spotlight on country 2016 playlist',\n",
              " 'add sugarolly days to my list  your favorite slaughterhouse',\n",
              " 'add this track to my global funk',\n",
              " 'add manuelita to my indiespensables playlist',\n",
              " 'add this artist to gretchen s soul revived playlist',\n",
              " 'put this song on my playlist  in the name of blues']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"AddToPlaylist\"][\"text\"].head(10).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBmwWhHXspEH"
      },
      "source": [
        "##### RateBook examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "w7La8pN-qm4y",
        "outputId": "6c929b5a-4dfc-421c-df22-5a48b2d44ef3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-789f5f704f38>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"RateBook\"][\"text\"].head(10).tolist()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i give this current textbook a rating value of 1 and a best rating of 6',\n",
              " 'rate this series a 5',\n",
              " 'give this novel 5 stars',\n",
              " 'i want to give this current textbook 4 points',\n",
              " 'rate this album a 1',\n",
              " 'rate in stars as a 6 for lord of the shadows which gets a four',\n",
              " 'rate my current book 1 out of 6',\n",
              " 'for the textbook  out of 6 possible i give the following one a 3',\n",
              " 'rate this book 0 out of 6',\n",
              " 'rate the current novel a 3']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"RateBook\"][\"text\"].head(10).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbun8erusuct"
      },
      "source": [
        "##### SearchScreeningEvent examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7OOlHf-QqnCh",
        "outputId": "e228e1b5-2473-461d-b3a9-c3908f88934b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b8e94c0178e1>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"SearchScreeningEvent\"][\"text\"].head(10).tolist()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['find fish story',\n",
              " 'give me a list of movie times for films in the area',\n",
              " 'find a movie house showing cage without a key',\n",
              " 'find animated movies nearest at a movie house',\n",
              " 'find me showtimes for animated movies in the neighbourhood',\n",
              " 'find movie times',\n",
              " 'show movie schedules for douglas theatre company',\n",
              " 'let me see the movie schedule for seed of chucky',\n",
              " 'in the area find some films',\n",
              " 'what times will the young swordsman be showing at a local cinema']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"SearchScreeningEvent\"][\"text\"].head(10).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiRtSmCWszDm"
      },
      "source": [
        "##### BookRestaurant examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gW_cWhqDqnNN",
        "outputId": "ba0f2f30-e135-47f1-8465-51c7fb94d96c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-e67137ffa432>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"BookRestaurant\"][\"text\"].head(10).tolist()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['book a spot for 3 in mt',\n",
              " 'book a restaurant for eight people in six years',\n",
              " 'i need to book a restaurant in fork mountain  sc for valarie  mari and i',\n",
              " 'book a restaurant at sixteen o clock in sc',\n",
              " 'i d like to go to the popular bistro in oh',\n",
              " 'book a taverna that serves vichyssoise within walking distance in oh',\n",
              " 'book a brasserie for one',\n",
              " 'i want to book a restaurant not far from our college',\n",
              " 'i d like to go to the venetian theatre in gabon  party of seven',\n",
              " 'book a reservation for a pub with ma po tofu in moldova']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"BookRestaurant\"][\"text\"].head(10).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0gyT9tbs5Lc"
      },
      "source": [
        "##### GetWeather examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xL_iKqhOqnWZ",
        "outputId": "c5e45448-13db-4660-aa4d-ea1365eeec6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-81c0d18a3f60>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"GetWeather\"][\"text\"].head(10).tolist()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i need a forecast for jetmore  massachusetts in 1 hour and 1 second from now',\n",
              " 'please let me know the weather forcast of stanislaus national forest far in nine months',\n",
              " 'what s the weather in my current spot the day after tomorrow',\n",
              " 'what is the weather like in the city of frewen in the country of venezuela',\n",
              " 'will it be colder in ohio',\n",
              " 'what is the weather not far from upper klamath national wildlife refuge',\n",
              " 'will it storm in charles pinckney national historic site',\n",
              " 'is it supposed to rain nearby my current location at 0 o clock',\n",
              " 'what is the weather supposed to be like in new jersey three months from now',\n",
              " 'will it be warmer now in covenant life']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"GetWeather\"][\"text\"].head(10).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkzIGFLAs8ix"
      },
      "source": [
        "##### SearchCreativeWork examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g4p6LY4cqnet",
        "outputId": "9f59b60d-beb2-449a-ab0b-f9e4024d65f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-60d6f95a99bb>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"SearchCreativeWork\"][\"text\"].head(10).tolist()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['show me the picture creatures of light and darkness',\n",
              " 'search for the adventures of cookie & cream',\n",
              " 'play hell house song',\n",
              " 'i d like to see the show onion sportsdome',\n",
              " 'find a video game called victory march',\n",
              " 'find a novel called industry',\n",
              " 'please find the movie dancing girl',\n",
              " 'find resurrection of evil',\n",
              " 'find playstation官方杂志  a song',\n",
              " 'find young miss holmes']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "intent_data[intent_data[\"split\"] == \"train\"][intent_data[\"intent\"] == \"SearchCreativeWork\"][\"text\"].head(10).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcCyWyTuzmCF"
      },
      "source": [
        "## Building a rule based classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks4pXmXhMxSo"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "To increase the generalisability of your system you can preprocess it to, for example, convert morphological variants to a single \"lemma\". You can do this by adding different substitution (re.sub) functions to the function below. The function as is stands doesn't do anything - you need to update the re.sub statements. This isn't an essential step as you can deal with variants in your patterns, but it will help to reduce redundancy in your classifier regular expressions which you may find helpful.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "hN5S4nkZtg96"
      },
      "outputs": [],
      "source": [
        "def preprocess_utterance(utt):\n",
        "  utt = re.sub(\"one\",\"1\", utt)\n",
        "  utt = re.sub(\"1 star\",\"1 stars\", utt)\n",
        "  utt = re.sub(\"1 point\",\"1 points\", utt)\n",
        "  utt = re.sub(\"schedules\",\"schedule\", utt)\n",
        "  utt = re.sub(\"taverna|tavern|pub|brasserie\",\"restaurant\", utt)\n",
        "  utt = re.sub(\"raining|rains\",\"rain\", utt)\n",
        "  utt = re.sub(\"snowing|snows\",\"snow\", utt)\n",
        "  utt = re.sub(\"show me\",\"showme\", utt)\n",
        "  utt = re.sub(\"find a\",\"finda\", utt)\n",
        "  utt = re.sub(\"\",\"\", utt)\n",
        "  return utt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-haCPpLEzF-U"
      },
      "source": [
        "You can test whether you patterns are working as intented using the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "cN1PE_VXzF-V",
        "outputId": "3c6501a4-05f1-4c32-ed62-191fc1c122e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a utterance to test your preprocessing on: brasserie\n",
            "restaurant\n"
          ]
        }
      ],
      "source": [
        "test_input = input(\"Enter a utterance to test your preprocessing on: \")\n",
        "print(preprocess_utterance(test_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxiA0Zn4tMhQ"
      },
      "source": [
        "### Define patterns\n",
        "\n",
        "The function below takes an utterance as input and applies a series of regular expressions to identify the intent of the speaker. The regular expressions currently just looks for keywords taken from the intent name. You should update these patterns to be more appropriate and capture a wider range of utterances for each intent.\n",
        "\n",
        "Each time you update the code you will need to run the code cell in order to then use the function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ0HamWjAzV_"
      },
      "source": [
        "The assign_intent function uses the re.findall function (see week 2) in order to make as many matches as possible with each pattern. The number of matches is then counted (using the len function) for each pattern. The intent with the largest number of matches is then returned as the predicted intent. Imagine for example that your patterns for PlayMusic and GetWeather were as follows: <br>\n",
        "PlayMusic_Pattern = re.compile(\"play|music\") <br>\n",
        "GetWeather_Pattern = re.compile(\"get|weather\") <br>\n",
        "while the input utterances was \"play some music by the weather girls\".\n",
        "In this case the PlayMusic pattern would match twice (for play and music) while the GetWeather pattern would only match once. PlayMusic would be returned as the predicted intent. Where there is a tie (as would happen if, for example, the input was simply \"play the weather girls\") a prediction is randomly sampled from among the tied intents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "GTaIRW-x4Ezb"
      },
      "outputs": [],
      "source": [
        "def assign_intent(utt, verbose=False):\n",
        "  PlayMusic_Pattern = re.compile(\"play|listen|music|chant|song|by|on\")\n",
        "  AddToPlaylist_Pattern = re.compile(\"add|this| to| my|playlist\")\n",
        "  RateBook_Pattern = re.compile(\"rate|book|stars|points|this\")\n",
        "  SearchScreeningEvent_Pattern = re.compile(\"find|movie|screening|times|showtimes|timings|schedule|area|neighbourhood|cinema\")\n",
        "  BookRestaurant_Pattern = re.compile(\"book|restaurant|for|people| in \")\n",
        "  GetWeather_Pattern = re.compile(\"what|will| get|weather|like|storm|rain|snow|cold|warm|colder|warmer\")\n",
        "  SearchCreativeWork_Pattern = re.compile(\"creative|find|called|showme|finda\")\n",
        "\n",
        "  weights = {}\n",
        "  weights['PlayMusic'] = len(re.findall(PlayMusic_Pattern,  utt))\n",
        "  weights['AddToPlaylist'] = len(re.findall(AddToPlaylist_Pattern,  utt))\n",
        "  weights['RateBook'] = len(re.findall(RateBook_Pattern,  utt))\n",
        "  weights['SearchScreeningEvent'] = len(re.findall(SearchScreeningEvent_Pattern,  utt))\n",
        "  weights['BookRestaurant'] = len(re.findall(BookRestaurant_Pattern,  utt))\n",
        "  weights['GetWeather'] = len(re.findall(GetWeather_Pattern,  utt))\n",
        "  weights['SearchCreativeWork'] = len(re.findall(SearchCreativeWork_Pattern,  utt))\n",
        "  if verbose:\n",
        "      print(weights)\n",
        "  if max(weights.values()) == 0:\n",
        "      return random.choice(list(weights.keys()))\n",
        "  else:\n",
        "      weights_as_list = list(weights.items())\n",
        "      random.shuffle(weights_as_list)\n",
        "      weights=dict(weights_as_list)\n",
        "      return max(weights, key=lambda key: weights[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cwzJHqDLokL"
      },
      "source": [
        "### Evaluation\n",
        "When you run this cell you will be asked to enter an utterance. When you press return the scores for each classification of your input will be printed. You can use this to check whether your preprocess_utterance and/or assign_intent functions are working as intended."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "WZqyRr_sIJvw",
        "outputId": "e1976b99-2dbd-4eee-c21b-643fab3805d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a utterance to classify: add this to my playlist\n",
            "{'PlayMusic': 1, 'AddToPlaylist': 5, 'RateBook': 1, 'SearchScreeningEvent': 0, 'BookRestaurant': 0, 'GetWeather': 0, 'SearchCreativeWork': 0}\n",
            "AddToPlaylist\n"
          ]
        }
      ],
      "source": [
        "new_input = input(\"Enter a utterance to classify: \")\n",
        "prediction = assign_intent(preprocess_utterance(new_input),verbose=True)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsec0kYpLh0s"
      },
      "source": [
        "In order to perform a stricter assessment of the performance of your classifier, you should examine its performance on the validation dataset. If you run the cell below you will be told the accuracy score on those 700 utterances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "pCDozgVm2XnZ",
        "outputId": "b7da49c4-7bef-4b3c-f9f6-55a8831662ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6814285714285714\n",
            "The highest score achieved so far is 0.7142857142857143\n"
          ]
        }
      ],
      "source": [
        "predicted = [assign_intent(preprocess_utterance(item)) for item in intent_data[intent_data['split'] == \"val\"]['text']]\n",
        "true = intent_data[intent_data['split'] == \"val\"]['intent']\n",
        "accuracy = (predicted == true).sum()/len(true)\n",
        "print(accuracy)\n",
        "\n",
        "#the highest accuracy achieved on training data calculator\n",
        "if accuracy > topscore:\n",
        "  topscore = accuracy\n",
        "\n",
        "print(\"The highest score achieved so far is \" + str(topscore))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topscore = 0.7142857142857143 #just for initializing, don't run or it will reset"
      ],
      "metadata": {
        "id": "iXGhCK9IkBnR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xajHmMX33-oC"
      },
      "source": [
        "Running the next cell will give you a \"confusion matrix\". This tells you the number of times that each intent as given in the rows is classified (correctly or otherwise) as each intent as represented by the columns. The columns are displayed as numbers but you can check which each of these numbers stands for by looking into the parentheses after each intent in the rows.\n",
        "\n",
        "Studying this will give you an idea of where the classifier might be going wrong, and therefore of how you might update your patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "j1t-etZ3L7iS",
        "outputId": "4e793abc-7b42-4065-86c9-13c44951ba99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           0   1   2   3   4   5   6\n",
            "AddToPlaylist (0)         92   0   2  12  12   9  11\n",
            "BookRestaurant (1)         1  96  39   1   4  25   9\n",
            "GetWeather (2)             0   0  50   1   2   6   5\n",
            "PlayMusic (3)              7   2   8  85   7  18  16\n",
            "RateBook (4)               0   2   0   0  75   2   0\n",
            "SearchCreativeWork (5)     0   0   1   1   0  22   2\n",
            "SearchScreeningEvent (6)   0   0   0   0   0  18  57\n"
          ]
        }
      ],
      "source": [
        "print(pd.DataFrame(confusion_matrix(predicted, true), index=[\"AddToPlaylist (0)\", \"BookRestaurant (1)\", \"GetWeather (2)\", \"PlayMusic (3)\", \"RateBook (4)\", \"SearchCreativeWork (5)\", \"SearchScreeningEvent (6)\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV9Py45v2HdG"
      },
      "source": [
        "Once you are happy that you have defined the best patterns that you can, you should evaluate the performance of your classifier on the test data (a set of 700 utterances that you haven't looked at). The accuracy printed is what you should include in your report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3DqHjOs02yk"
      },
      "outputs": [],
      "source": [
        "predicted = [assign_intent(preprocess_utterance(item)) for item in intent_data[intent_data['split'] == \"test\"]['text']]\n",
        "true = intent_data[intent_data['split'] == \"test\"]['intent']\n",
        "accuracy = (predicted == true).sum()/len(true)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvH8ufhD5fzd"
      },
      "source": [
        "You can also generate a confusion matrix for the test data and use this in the discussion of the results in your write up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODBNlsOQ5fEf"
      },
      "outputs": [],
      "source": [
        "print(pd.DataFrame(confusion_matrix(predicted, true), index=[\"AddToPlaylist (0)\", \"BookRestaurant (1)\", \"GetWeather (2)\", \"PlayMusic (3)\", \"RateBook (4)\", \"SearchCreativeWork (5)\", \"SearchScreeningEvent (6)\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbiBTPm2EWM_"
      },
      "source": [
        "## Single Layer Perceptron Classifier\n",
        "\n",
        "The next classifier you can build is single-layer perceptron. The specification of this model is in the next cell. You shouldn't make any changes to this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhqmeFunSxTY"
      },
      "outputs": [],
      "source": [
        "class IntentClassifierPerceptron(nn.Module):\n",
        "    \"\"\" a simple perceptron based classifier \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_features (int): the size of the input feature vector\n",
        "        \"\"\"\n",
        "        super(IntentClassifierPerceptron, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=True):\n",
        "        \"\"\"The forward pass of the classifier\n",
        "\n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor.\n",
        "                x_in.shape should be (batch, num_features)\n",
        "            apply_softmax (bool): a flag for the softmax activation\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch,)\n",
        "        \"\"\"\n",
        "\n",
        "        y_out = self.fc1(x_in)\n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out,dim=1)\n",
        "        return y_out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxIBFz42QIF2"
      },
      "source": [
        "### Preprocessing\n",
        "As with the rule-based model, to increase the generalisability of your system you can preprocess the text to, for example, convert morphological variants to a single \"lemma\". You can do ths by adding different substitution (re.sub) functions to the function below. The function as is stands doesn't do anything - you need to update the re.sub statements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJK3bcpeQIF-"
      },
      "outputs": [],
      "source": [
        "def preprocess_utterance(utt):\n",
        "  utt = re.sub(\"\",\"\", utt)\n",
        "  return utt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d7BwY4CQIF-"
      },
      "source": [
        "For this machine-learning-based model we are going to make the preprocessing changes to the data used, and this will involve making changes to the file we have saved. When we need to revert to the original unaltered file, we can then run the following cell."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DabzSQ_pc8dj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr2Uiq-YQIF_"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/intent_classification_with_splits.csv -O intent_classification_with_splits.csv\n",
        "!cp intent_classification_with_splits.csv /content/gdrive/My\\ Drive/Intent_Classification/\n",
        "intent_data=pd.read_csv('intent_classification_with_splits.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lltyd5emQIF_"
      },
      "source": [
        "You can check that your preprocessing patterns are doing what we want by testing them on examples using the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmmw5G5QQIF_"
      },
      "outputs": [],
      "source": [
        "test_input = input(\"Enter a utterance to test your preprocessing on: \")\n",
        "print(preprocess_utterance(test_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKxW9JpRQIF_"
      },
      "source": [
        "Once you are happy with your preprocessing you can then transform the text in the training, validation and test data using the following cell. This alters the data on the disk so if you want to undo any changes later you will have to revert to the original data (as described above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLg0h1JIQIF_"
      },
      "outputs": [],
      "source": [
        "intent_data=pd.read_csv('intent_classification_with_splits.csv')\n",
        "intent_data['text'] = [preprocess_utterance(item) for item in intent_data['text']]\n",
        "intent_data.to_csv('intent_classification_with_splits.csv', index=False)\n",
        "!cp intent_classification_with_splits.csv /content/gdrive/My\\ Drive/Intent_Classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkTtqltm6Ctc"
      },
      "source": [
        "### Training the model\n",
        "In order to first initialise your model and then train it, you should run the following cell. The training will take a minute or two to complete - the progress bars will tell you how far along it is.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj-qJML1ja7t"
      },
      "outputs": [],
      "source": [
        "params = initialise()\n",
        "classifier = IntentClassifierPerceptron(input_dim=len(params.vectorizer.text_vocab),output_dim=len(params.vectorizer.intent_vocab))\n",
        "train_state = trainModel(params, params.dataset, classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejmO5vhuHn72"
      },
      "source": [
        "### Test on individual utterance\n",
        "\n",
        "As with the rule-based classifier you can look at the performance of the system on a single example utterance. This can be used to see whether your preprocessing is helping to capture the cases you hoped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OEZKHmDKG2M"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "new_utterance = input(\"Enter a utterance to classify: \")\n",
        "classifier = classifier.to(\"cpu\")\n",
        "prediction = predict_intent(preprocess_utterance(new_utterance), classifier, params.vectorizer)\n",
        "print(\"{} -> {} (p={:0.2f})\".format(new_utterance,\n",
        "                                    prediction['intent'],\n",
        "                                    prediction['probability']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulIyMBO1qGfZ"
      },
      "source": [
        "### Evaluate performance on validation data\n",
        "In order to evaluate the performance of your system while you tweak your preprocessing you can evaluate performance on the validation data, and look at a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZjsKUtLldPL"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "predicted, true = evaluate(params, classifier, train_state, 'val')\n",
        "print(\"Test Accuracy: {:.2f}\".format(train_state['val_acc']))\n",
        "print(pd.DataFrame(confusion_matrix(predicted, true), index=[\"AddToPlaylist\", \"BookRestaurant\", \"GetWeather\", \"PlayMusic\", \"RateBook\", \"SearchCreativeWork\", \"SearchScreeningEvent\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGm1SE5ZqMis"
      },
      "source": [
        "### Evaluate performance on test data\n",
        "\n",
        "Once you are happy that model performance is as good as you can achieve with this model type you should evaluate its accuracy on the test data. You can also use the confusion matrix for error analysis in your write up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF4udyBOqDgy"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "predicted, true = evaluate(params, classifier, train_state, 'test')\n",
        "print(\"Test Accuracy: {:.2f}\".format(train_state['test_acc']))\n",
        "print(pd.DataFrame(confusion_matrix(predicted, true), index=[\"AddToPlaylist\", \"BookRestaurant\", \"GetWeather\", \"PlayMusic\", \"RateBook\", \"SearchCreativeWork\", \"SearchScreeningEvent\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmJWrOFBvwJf"
      },
      "source": [
        "## Multilayer neural network classifier\n",
        "\n",
        "The third kind of classifier that you should build is a two-layer neural network. The model is defined below. Again you don't need to change this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUfDaievThXH"
      },
      "outputs": [],
      "source": [
        "class IntentClassifierMLP(nn.Module):\n",
        "    \"\"\" a simple perceptron based classifier \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_features (int): the size of the input feature vector\n",
        "        \"\"\"\n",
        "        super(IntentClassifierMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=True):\n",
        "        \"\"\"The forward pass of the classifier\n",
        "\n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor.\n",
        "                x_in.shape should be (batch, num_features)\n",
        "            apply_softmax (bool): a flag for the softmax activation\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch,)\n",
        "        \"\"\"\n",
        "        intermediate_vector = F.relu(self.fc1(x_in))\n",
        "        prediction_vector = self.fc2(intermediate_vector)\n",
        "\n",
        "        if apply_softmax:\n",
        "            prediction_vector = F.softmax(prediction_vector,dim=1)\n",
        "        return prediction_vector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZCtR8k29BV6"
      },
      "source": [
        "### Preprocessing\n",
        "As with the previous models, to increase the generalisability of your system you can preprocess the text to, for example, convert morphological variants to a single \"lemma\". You can do ths by adding different substitution (re.sub) functions to the function below. The function as is stands doesn't do anything - you need to update the re.sub statements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzvODPtSF9up"
      },
      "outputs": [],
      "source": [
        "def preprocess_utterance(utt):\n",
        "  utt = re.sub(\"\",\"\", utt)\n",
        "  utt = re.sub(\"\",\"\", utt)\n",
        "  utt = re.sub(\"\",\"\", utt)\n",
        "  return utt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGYR060QAdXF"
      },
      "source": [
        "For this machine-learning-based model we are going to make the preprocessing changes to the data use, and this will involve making changes to the file we have saved. When we need to revert to the original unaltered file, we can then run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaMZzsyvAJyZ"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/cbannard/compling24/refs/heads/main/Intent_Classification/intent_classification_with_splits.csv -O intent_classification_with_splits.csv\n",
        "!cp intent_classification_with_splits.csv /content/gdrive/My\\ Drive/Intent_Classification/\n",
        "intent_data=pd.read_csv('intent_classification_with_splits.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KCskx_pBPn1"
      },
      "source": [
        "You can check that your preprocessing patterns are doing what we want by testing them on examples using the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLqEVhjxBWsX"
      },
      "outputs": [],
      "source": [
        "test_input = input(\"Enter a utterance to test your preprocessing on: \")\n",
        "print(preprocess_utterance(test_input))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpfyaMF1A8ra"
      },
      "source": [
        "Once you are happy with your preprocessing you can then transform the text in the training, validation and test data using the following cell. This alters the data on the disk so if you want to undo any changes later you will have to revert to the original data (as described above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrK4_EBB9bf7"
      },
      "outputs": [],
      "source": [
        "intent_data=pd.read_csv('intent_classification_with_splits.csv')\n",
        "intent_data['text'] = [preprocess_utterance(item) for item in intent_data['text']]\n",
        "intent_data.to_csv('intent_classification_with_splits.csv', index=False)\n",
        "!cp intent_classification_with_splits.csv /content/gdrive/My\\ Drive/Intent_Classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUYKpA_k7j8B"
      },
      "source": [
        "### Training model\n",
        "You can now move on to training the model using your preprocessed data.\n",
        "\n",
        "One important variable that you can change is the number of nodes to include in your hidden layer. You can set this parameter in the cell below. The default is 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2IqgaF072Wl"
      },
      "outputs": [],
      "source": [
        "n_hidden_dims = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYEM37XU8BT3"
      },
      "source": [
        "You can then initialise and train the model by running the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XN0GKp9eoNY"
      },
      "outputs": [],
      "source": [
        "params = initialise()\n",
        "classifier = IntentClassifierMLP(input_dim=len(params.vectorizer.text_vocab),hidden_dim=n_hidden_dims,output_dim=len(params.vectorizer.intent_vocab))\n",
        "train_state = trainModel(params, params.dataset, classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZwwWsWk8oks"
      },
      "source": [
        "The following cell allows you to look at the performance of the system on a single example utterance. This can be used to see whether your preprocessing (and/or your choice of hidden dimensions) is capturing the cases you hoped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lED2pnPpLDpj"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "new_utterance = input(\"Enter a utterance to classify: \")\n",
        "classifier = classifier.to(\"cpu\")\n",
        "prediction = predict_intent(preprocess_utterance(new_utterance), classifier, params.vectorizer)\n",
        "print(\"{} -> {} (p={:0.2f})\".format(new_utterance,\n",
        "                                    prediction['intent'],\n",
        "                                    prediction['probability']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9tEyVp9qv2F"
      },
      "source": [
        "### Evaluate model on validation data\n",
        "\n",
        "In order to evaluate the performance of your system while you tweak it you can evaluate performance on the validation data, and look at a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6y-UHQVquba"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "predicted, true = evaluate(params, classifier, train_state, 'val')\n",
        "print(\"Test Accuracy: {:.2f}\".format(train_state['val_acc']))\n",
        "print(pd.DataFrame(confusion_matrix(predicted, true), index=[\"AddToPlaylist\", \"BookRestaurant\", \"GetWeather\", \"PlayMusic\", \"RateBook\", \"SearchCreativeWork\", \"SearchScreeningEvent\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WQeZtjvq1gc"
      },
      "source": [
        "### Evaluate model on test data\n",
        "\n",
        "Once you are happy that model performance is as good as you can achieve with this model type you should evaluate its accuracy on the test data. You can also use the confusion matrix for error analysis in your write up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-EvHcvIqu6y"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "predicted, true = evaluate(params, classifier, train_state, 'test')\n",
        "print(\"Test Accuracy: {:.2f}\".format(train_state['test_acc']))\n",
        "print(pd.DataFrame(confusion_matrix(predicted, true), index=[\"AddToPlaylist\", \"BookRestaurant\", \"GetWeather\", \"PlayMusic\", \"RateBook\", \"SearchCreativeWork\", \"SearchScreeningEvent\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uivLXlpkzF-c"
      },
      "source": [
        "## That's it!\n",
        "\n",
        "Once you have run through all of this notebook, made all of the additions and changes you want, and run all of the experiments you want you should write up the results following the guidance [here]( https://www.dropbox.com/s/zlmbk60a4ei1jdh/Writing%20your%20Computational%20Linguistics%20Research%20Report.docx)\n",
        "\n",
        "Your report should be submitted via turnitin using the link on Blackboard.\n",
        "\n",
        "To repeat a couple of things from the top of the sheet:\n",
        "\n",
        "- Once you have completed your work in this notebook please create a PDF including all of your changes and include it in your submission. This is just so that I can check what you have done if it isn't clear from your report. You will not be marked on the quality of any code you might include.\n",
        "\n",
        "- Please feel free to ask any questions about any part of the coursework. So that my response can benefit everyone please do so using the Coursework Discussion board on Blackboard. You can find a link to this down the left of the module Blackboard page.\n",
        "\n",
        "I hope you find it an enjoyable and worthwhile exercise.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}